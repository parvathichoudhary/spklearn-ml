{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Logistic Regression is used when the dependent variable (target or y variable) is categorical.\n",
    "\n",
    "e.g\n",
    "- predict an email is spam or not\n",
    "- predict whether it's going to rain tomorrow or not\n",
    "\n",
    "We cannot use linear regression for these kind of problems as linear regressio is unbounded. To solve these kind of problems is where Logistic Regression is used. \n",
    "\n",
    "Instead of fitting a line to the data (as was the case in linear regression), logistic regression fits an 'S' shaped logistic function\n",
    "\n",
    "<img src='img/logistic-reg-1.png'/>\n",
    "\n",
    "When the weights are closer to 0, y value indicates \"Not Obese\" and as the weight increases the y value slowly starts moving upwards to the \"Obese\" category.\n",
    "\n",
    "Curve goes from 0 to 1\n",
    "\n",
    "<img src='img/logistic-reg-2.png'/>\n",
    "\n",
    "Consider a new point in the X-axis, there is a high probability that mouse is Obese\n",
    "\n",
    "<img src='img/logistic-reg-3.png'/>\n",
    "\n",
    "If we pick a point in the X-axis kind of in the middle, then 50% probability for the mouse to be Obese and so on.\n",
    "\n",
    "Just like linear regression, logistic regression can also work with multiple independent variables. And the independent variables can be categorical or continous"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Linear regression, we fit the line using \"least squares\" method. i.e. We minimize the sum of the squares of the residuals. We also use R¬≤ to compare simple models to complicated models.\n",
    "\n",
    "Logistic regression doesnt have any residuals and hence no least squares or R¬≤, instead it uses \"maximum likelihood\". Curve with the maximum likelihood is selected. We try fitting the curve that covers the maximum cordinates. \n",
    "\n",
    "In Linear regression, when we try the best fit line , the y value ranges from -infinity to +infinity. \n",
    "In Logistic regression, the y value as seen in the plot above ranges between 0 - 1 i.e. the probability values and that's a problem if we are trying to solve Logistic regression using Linear Models (Generalized linear models)\n",
    "<img src='img/logistic-reg-4.png'/>\n",
    "\n",
    "To solve the problem we can transform the y-axis from probability of obesity to the log(odds of obesity) as shown int he picture below\n",
    "<img src='img/logistic-reg-5.png'/>\n",
    "\n",
    "This transformation can be done using the <b>logit</b> function\n",
    "\n",
    "<img src='img/logistic-reg-6.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithms - A quick refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logarithm-1.png'/>\n",
    "\n",
    "<img src='img/logarithm-2.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odds & Log(Odds)\n",
    "\n",
    "Odds are not the same as probabilities.\n",
    "\n",
    "Odds are the ratio of something happening to something not happening.\n",
    "\n",
    "e.g - ratio of my team winning / my team not winning\n",
    "\n",
    "Probability is the ratio of something happening to everything that could happen.\n",
    "\n",
    "e.g - ratio of my team winning / my team winning and losing\n",
    "\n",
    "<img src='img/odds-1.png'/>\n",
    "\n",
    "In the above example,\n",
    "\n",
    "odds of winning = 5/3 = 1.7\n",
    "probability of winning = 5/8 = 0.625\n",
    "probability of losing = 3/8 = 0.375\n",
    "\n",
    "if we take the ratio of probability of winning to probability of losing i.e. (5/8) / (3/8) = 5/3 which is the same as odds.\n",
    "\n",
    "We can calculate the odds if we have the probability of winning. Let's call the probability of winning as 'p' then we can say\n",
    "\n",
    "odds = (p) / (1 - p)\n",
    "\n",
    "Why we need log(odds)\n",
    "\n",
    "consider how the odds of winning changes based on how worst the team goes, \n",
    "\n",
    "e.g. 1/4 = 0.25 , 1/8 = 0.124 , 1/32 = .03125 .. as the odds of winning goes from bad to worse , the value approaches 0. \n",
    "\n",
    "if the odds are against the team winning then the value will be between 0 and 1\n",
    "\n",
    "now let's consider how the odds of winning changes based on how the team performs better,\n",
    "\n",
    "e.g. 4/3 = 1.3 , 8/3 = 2.7 , 32/3 = 10.7\n",
    "\n",
    "If the odds are in favour of the team winning then the value will be between 1 and infinity\n",
    "\n",
    "<img src='img/odds-2.png'/>\n",
    "\n",
    "The magnitude of the odds of not in favour v/s in favour is not in the same scale and hence not symmetrical. Consider 1/6 and 6/1 in the below image\n",
    "\n",
    "<img src='img/odds-3.png'/>\n",
    "\n",
    "Now let's take log(odds) to make the whole thing symmetrical\n",
    "\n",
    "<img src='img/odds-4.png'/>\n",
    "\n",
    "Let's also quickly get introduced to the concept of 'odds ratio', consider the below dataset. \n",
    "The data represents 356 people\n",
    "- 29 of these people have cancer\n",
    "- 327 do not have cancer\n",
    "- 140 people have mutated gene\n",
    "- 216 people do not have mutated gene\n",
    "\n",
    "<img src='img/odds-6.png'/>\n",
    "\n",
    "We can use 'odds ratio' to determine if there is a relationship between mutated gene and cancer (if someone has mutated gene, are the odds higher that they have cancer ?)\n",
    "\n",
    "Given that the person have mutated gene, the odds that they have cancer are - 23/117\n",
    "Given that the person does not have mutated, gene the odds that they have cancer are - 6/210\n",
    "\n",
    "odds ratio = (23/117) / (6/210) = 6.88\n",
    "log(odds ratio) = log(6.88) = 1.93\n",
    "\n",
    "The odds ratio tells us that the odds are 6.88 times greater, the person with mutated gene also will have cancer\n",
    "\n",
    "Odds ratio and the log of the odd ratio are like R¬≤ , they indicate a relationship between two things. Just like R¬≤, the values corresponds to the effect size. i.e. larger value means that the mutated gene is a good predictor of cancer , smaller value means that the mutated gene is not a good predictor of cancer.\n",
    "\n",
    "Just like R¬≤, we need to know that if the relationship is statistically significant, people uses 3 ways to determine if the odds ratio (or the log(odds ratio)) is statistically significant\n",
    "\n",
    "- Fisher's Exact Test\n",
    "- Chi-Square Test\n",
    "- Wald Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit contd ...\n",
    "\n",
    "Going back to the previous discussion of calculating odds from the probabilities,\n",
    "\n",
    "<img src='img/odds-5.png'/>\n",
    "\n",
    "After the transformation the new y axis will change from -infinity to +infinity as the y axis is presenting logit (log of the odds). The new plot will also be a straight line as opposed to a curve.\n",
    "\n",
    "Now with logistic regression we can find the coefficients and errors. \n",
    "\n",
    "So far we were talking about a continous variable (weight) and it's relationship with obesity (categorical variable)\n",
    "\n",
    "Let's see how the concept applies to a categorical variable\n",
    "\n",
    "<img src='img/logistic-reg-7.png'/>\n",
    "\n",
    "This type of logistic regression is similar to how t-test is done using linear models\n",
    "\n",
    "<img src='img/logistic-reg-8.png'/>\n",
    "\n",
    "<img src='img/logistic-reg-9.png'/>\n",
    "\n",
    "We pair this equation with a design matrix to predict the size of the mouse given that it has normal or mutated version of the gene\n",
    "Design matrix : - first column corresponds to the values to be substituted for B1 and the second column corresponds to the value to be substituted for B2,\n",
    "\n",
    "<pre>\n",
    "| 1 0 |\n",
    "| 1 0 | \n",
    "| 1 0 |\n",
    "| 1 0 |\n",
    "| 1 1 |\n",
    "| 1 1 |\n",
    "| 1 1 |\n",
    "| 1 1 |\n",
    "</pre>\n",
    "\n",
    "<img src='img/logistic-reg-10.png'/>\n",
    "\n",
    "Now let's see how this concept of t-test is applied on logistic regression\n",
    "\n",
    "<img src='img/logistic-reg-11.png'/>\n",
    "\n",
    "<img src='img/logistic-reg-12.png'/>\n",
    "\n",
    "size = log(odds gene‚Çô‚Çí·µ£‚Çò‚Çê‚Çó) * B‚ÇÅ + (log(odds gene‚Çò·µ§‚Çú‚Çê‚Çú‚Çëùíπ) - log(odds gene‚Çô‚Çí·µ£‚Çò‚Çê‚Çó)) * B‚ÇÇ\n",
    "\n",
    "size = log(odds gene‚Çô‚Çí·µ£‚Çò‚Çê‚Çó) * B‚ÇÅ + (log(odds gene‚Çò·µ§‚Çú‚Çê‚Çú‚Çëùíπ / odds gene‚Çô‚Çí·µ£‚Çò‚Çê‚Çó) * B‚ÇÇ\n",
    "\n",
    "The second term here is log of odds ratio. It tells us, on a log scale, how much having the mutated gene increases(or decreases) the odds of mouse being obese \n",
    "\n",
    "When we solve the above equation with values, that's what we get as coefficients when we do logistic regression\n",
    "\n",
    "In short, in terms of coefficients, logistic regression is the exact same as good old linear models except the coeffcients are in terms of log(odds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best fit curve a.k.a finding the maximum likelihood\n",
    "\n",
    "<img src='img/logistic-reg-13.PNG'/>\n",
    "\n",
    "We transform the y axis from probability of obesity to the log(odds of obesity). We cannot use least square in the new plot to get the best fit line because the residuals (distance from the data points to the line) are also infinity.\n",
    "\n",
    "<img src='img/logistic-reg-14.PNG'/>\n",
    "\n",
    "Instead of least squares we use maximum likelihood.\n",
    "\n",
    "We project the original data points onto the candidate line. This gives each point a log odds value.\n",
    "\n",
    "<img src='img/logistic-reg-15.PNG'/>\n",
    "\n",
    "We can transofrm the candidate log(odds) to candidate probabilities by  using this formulae\n",
    "\n",
    "p = eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ / ( 1 + eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ)\n",
    "\n",
    "<img src='img/logistic-reg-16.PNG'/>\n",
    "\n",
    "Basically if we have probability as input, then we can convert them to log(odds) and if we have log(odds) as input we can transform back to probability. Let's figure out how we arrived at this formulae\n",
    "\n",
    "log(p/(1-p)) = log(odds)\n",
    "\n",
    "p / (1-p) = eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ\n",
    "\n",
    "p = (1-p) * eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ \n",
    "\n",
    "p = eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ - p * eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ\n",
    "\n",
    "p + p * eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ =  eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ\n",
    "\n",
    "p * (1 + eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ) = eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ\n",
    "\n",
    "p = eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ / ( 1 + eÀ°·µí·µç‚ÅΩ·µí·µà·µàÀ¢‚Åæ)\n",
    "\n",
    "Now, for each points, pick the value on the y-axis , find the p value , plot the squiggle line.\n",
    "\n",
    "Find the likelyhood of each mouse being obese looking at the probability value. \n",
    "\n",
    "Likelyhood for all of the obese mouse are the product of individual likelyhoods.\n",
    "\n",
    "<img src='img/logistic-reg-17.PNG'/>\n",
    "\n",
    "Although it's possible to calculate the likelihood as the product of the individual likelihoods, statisticians prefer to calculate the log of the likelihood instead. The squiggle that maximizes the likelihood is the same as the one that maximizes the log of the likelihood\n",
    "\n",
    "log(likelihood of data given the squiggle) = log(0.49) + log(0.9) + log(0.91) + log(0.91) + log(0.92) + log(1-0.9) + log(1-0.3) + log(1-0.01) + log(1-0.01) \n",
    "\n",
    "Note - finding log (a * b ) = log a + log b\n",
    "\n",
    "Now we keep repeating the process till we find the best(maximizes) likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Found best fit curve - but how do we know it's useful ?\n",
    "\n",
    "Like how R¬≤ provides a way to measure how useful the fit is, in Logistic Regression we can use log-likelihood (LL) as a measure.\n",
    "\n",
    "We can use LL(fit) for the fitted line just like how we did SS(fit) for the fitted line in linear regression.\n",
    "\n",
    "We have to find something similar to SS(mean) in linear regression which tells us the poorly fitted line.\n",
    "\n",
    "We can find the log of odds of obesity for all the mice without considering weights. In the above example log(5/4) = 0.22. We get a horizontal line parallel to x and passing through y at point 0.22\n",
    "\n",
    "We project the data onto this line, find the probability and plot the probability squiggle\n",
    "\n",
    "<img src='img/logistic-reg-18.png'/>\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "<img src='img/logistic-reg-19.png'/>\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "<img src='img/logistic-reg-20.png'/>\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "<img src='img/logistic-reg-21.png'/>\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "<img src='img/logistic-reg-22.png'/>\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Like in Linear Regression, even for Logistic Regression R¬≤ value falls between 0 and 1 (0 when fit is bad and 1 when fit is best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for classification algorithms\n",
    "\n",
    "In Regression algorithm we find the accuracy metrics using,\n",
    "- MSE\n",
    "- RMSE\n",
    "- MAE\n",
    "- MAPE\n",
    "- R¬≤\n",
    "\n",
    "In Classification algorithm we find the accuracy metrics using,\n",
    "- Confusion matrix\n",
    "- proba graphs\n",
    "- ROC AUC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "- <b>True Positives</b> - These are patients that got heart disease and was correctly identified by algorithm\n",
    "- <b>True Negatives</b> - These are patients that did not have heard disease and was correctly identified by algorithm\n",
    "- <b>False Negatives</b> - Patients has heart disease but algorithm said they didnt\n",
    "- <b>False Positives</b> - Patients do not have heart disease but algorithm said they do\n",
    "\n",
    "Associate \n",
    "True -> Model predicting correctly | False -> Model predicting incorrectly\n",
    "Positive -> With heart condition | Negative -> Without heart condition\n",
    "\n",
    "- True's are correct predictions \n",
    "- False's are incorrect predictions\n",
    "    - False Negative - is incorrect Negative prediction. i.e. actual condition is positive.\n",
    "    - False Positive - is incorrect Positive prediction. i.e actual condition is negative.\n",
    "\n",
    "<img src='img/confmatrix-1.png'/>\n",
    "\n",
    "We can run multiple models (e.g KNN , Random Forest), create the confusion matrix and then see which one performs the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC Curve\n",
    "\n",
    "ROC - Receiver Operations Characteristics\n",
    "AUC - Area Under Curve\n",
    "\n",
    "In the graphs seen earlier for Logistic Regression the Y axis represents the probability values.\n",
    "\n",
    "<img src='img/roc-1.png'/>\n",
    "\n",
    "We can define a threshold line (say at y = 0.5) above which we shall classify all mice as obese and below which the mice will be classified as not obese. Now when a new observation comes it's easier to predict the class based on the probability. But, how do we find the perfect threshold forms the crux of the problem\n",
    "\n",
    "Consider the 8 new data (4 obese and 4 non obese mice) for which we know the classification already and we try to run it through the model using the threshold 0.5\n",
    "\n",
    "<img src='img/roc-2.png'/>\n",
    "\n",
    "As we run through the classification, we see that \n",
    "- 3 non obese mice is predicted correctly\n",
    "- 3 obese mice is predicted correctly\n",
    "- 1 non obese is predcited as obese\n",
    "- 1 obese is predicted as non-obese\n",
    "\n",
    "<img src='img/roc-3.png'/>\n",
    "\n",
    "We plot a confusion matrix with these numbers\n",
    "\n",
    "<img src='img/roc-4.png'/>\n",
    "\n",
    "Now it's clear that if we play around with the threshold value (any value between 0 and 1) we get a whole bunch of confusion matrices to choose from. Based on the problem statement in hand (e.g cancer detection - we dont want to miss catching any cases which means False Positives are acceptable) we have to find an optimum threshold. How do we find the best threshold ? That's where ROC curve comes in handy\n",
    "\n",
    "ROC Curve - is a graph between FPR (False Positive Rate) & TPR (True Positive Rate)\n",
    "\n",
    "TPR (Sensitivity) = (True Positives) / (True Positives + False Negatives)\n",
    "\n",
    "FPR (1 - Specificity) = (False Positives) / (False Positives + True Negatives)\n",
    "\n",
    "<img src='img/roc-5.png'/>\n",
    "\n",
    "Green diagonal line shows where the TPR = FPR. \n",
    "Like you see, we plot the ROC curve with changing thresholds and thereby computing new TPRs and FPRs. \n",
    "\n",
    "The top most point on the y axis shows that model correctly classified 75% of the obese samples and 100% of the non obese samples.\n",
    "\n",
    "ROC graph summarizes all of the confusion matrices each of the threshold produced.\n",
    "\n",
    "<b> AUC - Area Under the Curve </b>\n",
    "Higher the area under the curve better is the curve.\n",
    "\n",
    "If red ROC curve represents logistic regression and blue represents random forest, we can choose logistic regression.\n",
    "\n",
    "<img src='img/auc-1.png'/>\n",
    "\n",
    "Note : instead of using FPR people might use precision\n",
    "Precision = (True Positives) / (True Positives + False Positives)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification\n",
    "\n",
    "When we have 2 values in the y variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi class classification\n",
    "\n",
    "We can use an approach called <b>one v/s rest classifier</b>\n",
    "\n",
    "Let's say the y variable has values like 1,2,3 then it's a multi class classification problem.. \n",
    "\n",
    "Approach is going to be as follows,\n",
    "\n",
    "- Take all the rows from the training data where y=1. Let's assume there are 'n' rows. Flag the new y value as 'yes'\n",
    "- Take 'n' rows from the remaining dataset which will have values other than y=1. Flag the y value for this set as 'no'\n",
    "- Fit the data into a model (say model1) \n",
    "- Repeat the above steps for y=2 and y=3\n",
    "- After the models are fitted for y=1,2,3 we have 3 models (model1, model2, model3) who can classify 1,2,3 respectively.\n",
    "- The test data will be passed to the predict method of all the 3 models. The model giving the highest probability for 'yes' will be chosen and the 'y' variable it's trained to predict for will be the predicted 'y'variable. An example is given below which will clarify this further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  5  8  3  4  1\n",
       "1  1  6  6  1  0\n",
       "2  3  6  0  5  2\n",
       "3  8  2  1  0  2\n",
       "4  3  6  7  6  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.DataFrame(np.random.randint(0,10,(1000,5)))\n",
    "data[4]=np.random.randint(0,3,1000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (1000, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data[4]\n",
    "x=data.drop(4,axis=1)\n",
    "y.shape,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 0, 1, 0, 0, 0, 2,\n",
       "       0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 0, 2, 2, 2, 1, 2, 0, 0, 1, 2, 1, 2,\n",
       "       0, 2, 2, 1, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2,\n",
       "       0, 0, 2, 2, 1, 2, 2, 0, 1, 2, 1, 2, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2,\n",
       "       2, 0, 0, 2, 1, 1, 2, 2, 0, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2, 1, 2, 2,\n",
       "       2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 1, 0, 2, 0, 2, 2, 0, 2,\n",
       "       2, 0, 2, 1, 2, 1, 2, 0, 2, 0, 2, 0, 0, 0, 0, 1, 0, 2, 1, 0, 2, 2,\n",
       "       2, 2, 2, 2, 0, 0, 1, 1, 2, 0, 2, 0, 2, 0, 2, 2, 1, 0, 0, 0, 2, 2,\n",
       "       0, 2, 1, 0, 1, 2, 1, 1, 2, 0, 2, 1, 2, 0, 1, 1, 2, 0, 2, 2, 0, 0,\n",
       "       0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 1, 0, 1,\n",
       "       2, 2, 2, 1, 2, 2, 0, 2, 2, 1, 1, 1, 0, 2, 1, 0, 0, 2, 2, 2, 2, 0,\n",
       "       0, 1, 2, 2, 1, 0, 1, 2, 0, 2, 2, 0, 1, 1, 0, 2, 2, 2, 1, 2, 0, 1,\n",
       "       2, 1, 0, 2, 2, 1, 0, 2, 2, 0, 2, 0, 0, 2, 1, 2, 2, 1, 0, 0, 2, 0,\n",
       "       2, 0, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2,\n",
       "       2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 2,\n",
       "       0, 1, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 1, 1, 2, 1, 2, 0, 1, 0,\n",
       "       1, 2, 2, 2, 2, 0, 2, 2, 0, 1, 2, 2, 2, 0, 0, 2, 2, 0, 1, 1, 0, 2,\n",
       "       0, 2, 0, 1, 2, 2, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 2, 2, 2,\n",
       "       2, 0, 1, 2, 1, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 1, 0,\n",
       "       2, 2, 2, 0, 2, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 1, 1, 2, 2, 0, 0, 0,\n",
       "       0, 2, 2, 0, 0, 1, 0, 2, 2, 2, 2, 2, 0, 1, 2, 2, 1, 0, 2, 0, 2, 2,\n",
       "       2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 1, 2, 1, 2, 2, 1, 0, 0, 2, 1, 0, 2,\n",
       "       1, 2, 1, 2, 0, 0, 1, 2, 1, 2, 1, 0, 2, 0, 2, 2, 1, 0, 2, 0, 0, 1,\n",
       "       0, 2, 0, 2, 2, 2, 1, 0, 1, 2, 2, 1, 2, 2, 2, 0, 0, 0, 2, 1, 0, 2,\n",
       "       1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 2, 1, 2, 2, 1, 2, 2, 2, 0, 2, 0, 0,\n",
       "       1, 0, 2, 2, 0, 2, 1, 1, 2, 0, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 2, 2,\n",
       "       1, 2, 2, 2, 2, 1, 2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 1, 0, 2,\n",
       "       0, 2, 2, 0, 2, 0, 1, 2, 2, 1, 0, 2, 0, 2, 1, 0, 2, 2, 2, 2, 0, 0,\n",
       "       2, 1, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 0, 1, 0, 2, 0, 2, 1, 2, 0, 0,\n",
       "       2, 0, 0, 0, 2, 0, 2, 1, 0, 2, 0, 2, 1, 2, 0, 2, 2, 1, 2, 2, 2, 1,\n",
       "       2, 2, 1, 0, 2, 1, 2, 2, 1, 0, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       0, 2, 2, 1, 2, 1, 0, 2, 0, 2, 0, 2, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 0, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2,\n",
       "       0, 2, 2, 0, 2, 1, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 1, 0, 2, 1, 2, 1,\n",
       "       1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 0, 2, 1, 1, 0, 2, 2, 2, 0, 2,\n",
       "       0, 2, 2, 0, 2, 1, 1, 1, 0, 0, 1, 2, 0, 0, 2, 2, 0, 2, 1, 0, 1, 2,\n",
       "       2, 1, 1, 0, 2, 0, 2, 0, 1, 2, 0, 2, 0, 2, 2, 0, 2, 0, 1, 2, 2, 2,\n",
       "       2, 0, 2, 0, 1, 1, 2, 2, 1, 1, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1, 1,\n",
       "       1, 1, 1, 0, 2, 0, 1, 1, 2, 1, 0, 2, 1, 2, 0, 0, 0, 1, 2, 2, 0, 2,\n",
       "       2, 2, 0, 1, 2, 1, 0, 2, 0, 2, 2, 0, 0, 1, 0, 2, 2, 1, 2, 0, 0, 2,\n",
       "       2, 1, 1, 0, 1, 2, 2, 2, 2, 2, 1, 0, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 0, 1, 0, 1, 2, 2, 0, 0, 2, 0, 0, 2, 0, 1, 2, 2, 2, 2, 2, 0,\n",
       "       1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 2, 1, 2, 0,\n",
       "       1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 0, 2, 0, 2, 1, 2, 1, 2, 2, 0, 2, 2,\n",
       "       1, 1, 1, 0, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 0, 0, 1, 2, 0, 1, 0,\n",
       "       2, 0, 2, 0, 0, 0, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data[4]\n",
    "x=data.drop(4,axis=1)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x,y)\n",
    "lr.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4\n",
       "0    5  8  3  4  1\n",
       "1    1  6  6  1  0\n",
       "2    3  6  0  5  2\n",
       "3    8  2  1  0  2\n",
       "4    3  6  7  6  0\n",
       "..  .. .. .. .. ..\n",
       "995  9  7  1  7  0\n",
       "996  4  7  4  5  1\n",
       "997  1  9  0  4  1\n",
       "998  4  5  6  5  2\n",
       "999  3  2  9  0  0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((337, 5), (663, 5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d2=data[data[4]!=0].sample(d1.shape[0])\n",
    "d0_yes = data[data[4] == 0]\n",
    "d0_no = data[data[4] != 0]\n",
    "d0_yes.shape, d0_no.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((337, 5), (337, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take equal number of samples for y != 0 as y = 0\n",
    "d0_no = data[data[4]!=0].sample(d0_yes.shape[0])\n",
    "d0_yes.shape, d0_no.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['yes' 'No'] (322, 5) (322, 5) (644, 5)\n",
      "0 ['yes' 'No'] (337, 5) (337, 5) (674, 5)\n",
      "2 ['yes' 'No'] (341, 5) (341, 5) (682, 5)\n"
     ]
    }
   ],
   "source": [
    "predict_values=[]\n",
    "test_dataset=pd.DataFrame(np.random.randint(10,100,(100,4)))\n",
    "for i in data[4].unique():\n",
    "    d1=data[data[4]==i]\n",
    "    d1[4]=\"yes\"\n",
    "    d2=data[data[4]!=i].sample(d1.shape[0])\n",
    "    d2[4]=\"No\"\n",
    "    \n",
    "    final_dataset=d1.append(d2)\n",
    "    print(i,final_dataset[4].unique(),d1.shape,d2.shape,final_dataset.shape)\n",
    "    y=final_dataset[4]\n",
    "    x=final_dataset.drop(4,axis=1)\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    lr=LogisticRegression()\n",
    "    lr.fit(x,y)\n",
    "    \n",
    "    predict_values.append(lr.predict_proba(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49675417, 0.50324583],\n",
       "       [0.14853238, 0.85146762],\n",
       "       [0.01935312, 0.98064688],\n",
       "       [0.03418572, 0.96581428],\n",
       "       [0.11773769, 0.88226231],\n",
       "       [0.22072973, 0.77927027],\n",
       "       [0.12228571, 0.87771429],\n",
       "       [0.16933556, 0.83066444],\n",
       "       [0.53618424, 0.46381576],\n",
       "       [0.01256422, 0.98743578],\n",
       "       [0.1864411 , 0.8135589 ],\n",
       "       [0.71906647, 0.28093353],\n",
       "       [0.44459149, 0.55540851],\n",
       "       [0.19153542, 0.80846458],\n",
       "       [0.26659083, 0.73340917],\n",
       "       [0.22982042, 0.77017958],\n",
       "       [0.4678813 , 0.5321187 ],\n",
       "       [0.7783377 , 0.2216623 ],\n",
       "       [0.52221452, 0.47778548],\n",
       "       [0.43491274, 0.56508726],\n",
       "       [0.02020308, 0.97979692],\n",
       "       [0.2107718 , 0.7892282 ],\n",
       "       [0.1250816 , 0.8749184 ],\n",
       "       [0.38601765, 0.61398235],\n",
       "       [0.44227896, 0.55772104],\n",
       "       [0.14582325, 0.85417675],\n",
       "       [0.26052121, 0.73947879],\n",
       "       [0.42844235, 0.57155765],\n",
       "       [0.61118175, 0.38881825],\n",
       "       [0.4604117 , 0.5395883 ],\n",
       "       [0.0223563 , 0.9776437 ],\n",
       "       [0.6914623 , 0.3085377 ],\n",
       "       [0.07204807, 0.92795193],\n",
       "       [0.90216906, 0.09783094],\n",
       "       [0.01555803, 0.98444197],\n",
       "       [0.43702324, 0.56297676],\n",
       "       [0.03197914, 0.96802086],\n",
       "       [0.07628357, 0.92371643],\n",
       "       [0.09739752, 0.90260248],\n",
       "       [0.4160632 , 0.5839368 ],\n",
       "       [0.43661137, 0.56338863],\n",
       "       [0.77432011, 0.22567989],\n",
       "       [0.36896854, 0.63103146],\n",
       "       [0.435572  , 0.564428  ],\n",
       "       [0.09696798, 0.90303202],\n",
       "       [0.42333516, 0.57666484],\n",
       "       [0.74126198, 0.25873802],\n",
       "       [0.32976231, 0.67023769],\n",
       "       [0.19523226, 0.80476774],\n",
       "       [0.13921848, 0.86078152],\n",
       "       [0.04128972, 0.95871028],\n",
       "       [0.00721923, 0.99278077],\n",
       "       [0.15276869, 0.84723131],\n",
       "       [0.09235925, 0.90764075],\n",
       "       [0.33613607, 0.66386393],\n",
       "       [0.07647514, 0.92352486],\n",
       "       [0.20683687, 0.79316313],\n",
       "       [0.611925  , 0.388075  ],\n",
       "       [0.04752793, 0.95247207],\n",
       "       [0.11787671, 0.88212329],\n",
       "       [0.08327163, 0.91672837],\n",
       "       [0.10849618, 0.89150382],\n",
       "       [0.26950262, 0.73049738],\n",
       "       [0.06488438, 0.93511562],\n",
       "       [0.43180274, 0.56819726],\n",
       "       [0.40448648, 0.59551352],\n",
       "       [0.45034832, 0.54965168],\n",
       "       [0.03203262, 0.96796738],\n",
       "       [0.71903965, 0.28096035],\n",
       "       [0.11028006, 0.88971994],\n",
       "       [0.14037595, 0.85962405],\n",
       "       [0.65270696, 0.34729304],\n",
       "       [0.43489404, 0.56510596],\n",
       "       [0.13275994, 0.86724006],\n",
       "       [0.16359865, 0.83640135],\n",
       "       [0.11816091, 0.88183909],\n",
       "       [0.21680529, 0.78319471],\n",
       "       [0.121143  , 0.878857  ],\n",
       "       [0.06083995, 0.93916005],\n",
       "       [0.04736807, 0.95263193],\n",
       "       [0.08689836, 0.91310164],\n",
       "       [0.04098495, 0.95901505],\n",
       "       [0.23126304, 0.76873696],\n",
       "       [0.00977938, 0.99022062],\n",
       "       [0.59311358, 0.40688642],\n",
       "       [0.10823352, 0.89176648],\n",
       "       [0.04351116, 0.95648884],\n",
       "       [0.45076585, 0.54923415],\n",
       "       [0.14678102, 0.85321898],\n",
       "       [0.1154082 , 0.8845918 ],\n",
       "       [0.18724872, 0.81275128],\n",
       "       [0.51642178, 0.48357822],\n",
       "       [0.01372792, 0.98627208],\n",
       "       [0.06520619, 0.93479381],\n",
       "       [0.68670725, 0.31329275],\n",
       "       [0.25643078, 0.74356922],\n",
       "       [0.66037883, 0.33962117],\n",
       "       [0.62097736, 0.37902264],\n",
       "       [0.10998807, 0.89001193],\n",
       "       [0.66308891, 0.33691109]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_values[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 100, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_values=np.array(predict_values)\n",
    "predict_values.shape\n",
    "\n",
    "# 3 model outputs \n",
    "# each model output has 100 rows and 2 columns \n",
    "# first column is probability of 'yes' and second column is probability of 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from each model output take the first column alone i.e. the probability of 'yes' and combine them\n",
    "coordinates=list(zip(predict_values[0][:,0],predict_values[1][:,0],predict_values[2][:,0]))\n",
    "coordinates=np.array(coordinates)\n",
    "# coordinates is holding the probability of 'yes' from all the 3 models. Pick the one with maximum probability\n",
    "coordinates.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98988895, 0.69738051, 0.01899272],\n",
       "       [0.96256411, 0.70076047, 0.06323923],\n",
       "       [0.94966665, 0.66557807, 0.53931507],\n",
       "       [0.96955348, 0.79523224, 0.04354932],\n",
       "       [0.97076093, 0.51987905, 0.10906437],\n",
       "       [0.93377472, 0.50296839, 0.5480513 ],\n",
       "       [0.92252093, 0.35862915, 0.74827202],\n",
       "       [0.93677996, 0.48390685, 0.58708876],\n",
       "       [0.98853996, 0.60584622, 0.24246191],\n",
       "       [0.97940182, 0.72922648, 0.04361155],\n",
       "       [0.98255276, 0.60715601, 0.04496913],\n",
       "       [0.98801244, 0.70848785, 0.02826812],\n",
       "       [0.98425349, 0.56299503, 0.09684469],\n",
       "       [0.76519471, 0.56125072, 0.71872673],\n",
       "       [0.8990476 , 0.51933953, 0.49998503],\n",
       "       [0.95229961, 0.41464397, 0.60550754],\n",
       "       [0.992032  , 0.62413924, 0.05556112],\n",
       "       [0.88983425, 0.70422782, 0.14800316],\n",
       "       [0.83078783, 0.42144152, 0.81102718],\n",
       "       [0.85358153, 0.52708833, 0.51819678],\n",
       "       [0.96968608, 0.58139561, 0.1809676 ],\n",
       "       [0.971646  , 0.58993199, 0.21162826],\n",
       "       [0.83068945, 0.5411209 , 0.55736979],\n",
       "       [0.88143471, 0.54393741, 0.31860938],\n",
       "       [0.97691992, 0.52175547, 0.35091799],\n",
       "       [0.86489642, 0.39634347, 0.82130211],\n",
       "       [0.88592104, 0.67452925, 0.13141891],\n",
       "       [0.91686959, 0.67222118, 0.10771378],\n",
       "       [0.99129932, 0.63699258, 0.02707588],\n",
       "       [0.96605724, 0.50033744, 0.11423012],\n",
       "       [0.98419142, 0.60545398, 0.09888775],\n",
       "       [0.98697907, 0.82060741, 0.0133582 ],\n",
       "       [0.99244329, 0.74120208, 0.0551898 ],\n",
       "       [0.98489968, 0.59444573, 0.02505404],\n",
       "       [0.95433713, 0.47325292, 0.2766114 ],\n",
       "       [0.97721743, 0.61476144, 0.43311788],\n",
       "       [0.98803673, 0.69586931, 0.02835402],\n",
       "       [0.99089759, 0.64630736, 0.09255992],\n",
       "       [0.91382675, 0.65913112, 0.23291912],\n",
       "       [0.97767478, 0.81357042, 0.0239572 ],\n",
       "       [0.77258653, 0.6283936 , 0.39465115],\n",
       "       [0.99284632, 0.79716284, 0.01195926],\n",
       "       [0.9906579 , 0.75927109, 0.0403566 ],\n",
       "       [0.80157394, 0.42352111, 0.88087705],\n",
       "       [0.59792237, 0.63577771, 0.76493701],\n",
       "       [0.98999352, 0.63850901, 0.04998772],\n",
       "       [0.95007474, 0.46417983, 0.57444707],\n",
       "       [0.9704848 , 0.80825437, 0.04926921],\n",
       "       [0.62705713, 0.6466711 , 0.61013646],\n",
       "       [0.92436537, 0.4915756 , 0.23576719],\n",
       "       [0.70332542, 0.52355321, 0.71433851],\n",
       "       [0.99372203, 0.66182889, 0.12375566],\n",
       "       [0.99189682, 0.73843299, 0.05512356],\n",
       "       [0.99041985, 0.62240039, 0.06669117],\n",
       "       [0.99374542, 0.8111784 , 0.00980515],\n",
       "       [0.99809848, 0.73566323, 0.00883132],\n",
       "       [0.99327533, 0.73150372, 0.09843093],\n",
       "       [0.97251202, 0.81643711, 0.01485524],\n",
       "       [0.98247703, 0.56568152, 0.14657969],\n",
       "       [0.97729827, 0.53583425, 0.38058243],\n",
       "       [0.96489997, 0.66979911, 0.07531404],\n",
       "       [0.90603374, 0.51545153, 0.21767601],\n",
       "       [0.99701422, 0.70397414, 0.00640295],\n",
       "       [0.81772913, 0.66502419, 0.45534869],\n",
       "       [0.99179025, 0.70817465, 0.05134991],\n",
       "       [0.82494646, 0.63259549, 0.63254812],\n",
       "       [0.96892296, 0.45732301, 0.13554846],\n",
       "       [0.96611282, 0.60383433, 0.3742283 ],\n",
       "       [0.46201245, 0.60353089, 0.86576979],\n",
       "       [0.97778611, 0.66083906, 0.15654005],\n",
       "       [0.98408221, 0.72582609, 0.12385318],\n",
       "       [0.43316965, 0.56020194, 0.9231926 ],\n",
       "       [0.99694464, 0.68733746, 0.01358618],\n",
       "       [0.48490609, 0.47197223, 0.86550178],\n",
       "       [0.82731934, 0.37749489, 0.858901  ],\n",
       "       [0.96190484, 0.79574092, 0.11079005],\n",
       "       [0.4404464 , 0.53403101, 0.87930418],\n",
       "       [0.74492548, 0.41272959, 0.84130191],\n",
       "       [0.95314617, 0.76499724, 0.03453358],\n",
       "       [0.99472323, 0.69218282, 0.01154875],\n",
       "       [0.99095711, 0.64675452, 0.16819259],\n",
       "       [0.81578022, 0.639541  , 0.38098065],\n",
       "       [0.99066747, 0.69284449, 0.19908129],\n",
       "       [0.83219672, 0.61169228, 0.42178503],\n",
       "       [0.97954344, 0.62090981, 0.11237121],\n",
       "       [0.97615182, 0.70221252, 0.05934771],\n",
       "       [0.94229524, 0.75974819, 0.2347615 ],\n",
       "       [0.79173633, 0.48857058, 0.66012251],\n",
       "       [0.91484045, 0.63370758, 0.15732226],\n",
       "       [0.70793749, 0.63982511, 0.68715614],\n",
       "       [0.97751994, 0.48256476, 0.25294123],\n",
       "       [0.99189653, 0.68572134, 0.01838577],\n",
       "       [0.94467378, 0.37950717, 0.21910739],\n",
       "       [0.99521053, 0.75587114, 0.01326142],\n",
       "       [0.95886518, 0.69795853, 0.1915703 ],\n",
       "       [0.98563877, 0.62462818, 0.04804198],\n",
       "       [0.93976011, 0.72848155, 0.07288226],\n",
       "       [0.94521343, 0.47734287, 0.46793231],\n",
       "       [0.9860764 , 0.40785836, 0.09123778],\n",
       "       [0.9485348 , 0.73030852, 0.078722  ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97709031, 0.02290969],\n",
       "       [0.95418512, 0.04581488],\n",
       "       [0.89550491, 0.10449509],\n",
       "       [0.97929285, 0.02070715],\n",
       "       [0.92155804, 0.07844196],\n",
       "       [0.93452805, 0.06547195],\n",
       "       [0.92693005, 0.07306995],\n",
       "       [0.95787465, 0.04212535],\n",
       "       [0.93992463, 0.06007537],\n",
       "       [0.99619211, 0.00380789],\n",
       "       [0.97817384, 0.02182616],\n",
       "       [0.94283052, 0.05716948],\n",
       "       [0.97880807, 0.02119193],\n",
       "       [0.78512915, 0.21487085],\n",
       "       [0.96915552, 0.03084448],\n",
       "       [0.93841656, 0.06158344],\n",
       "       [0.90898377, 0.09101623],\n",
       "       [0.85627968, 0.14372032],\n",
       "       [0.96143279, 0.03856721],\n",
       "       [0.97777035, 0.02222965],\n",
       "       [0.99379601, 0.00620399],\n",
       "       [0.99432379, 0.00567621],\n",
       "       [0.98392006, 0.01607994],\n",
       "       [0.96387818, 0.03612182],\n",
       "       [0.99339099, 0.00660901],\n",
       "       [0.97057733, 0.02942267],\n",
       "       [0.95454852, 0.04545148],\n",
       "       [0.97492076, 0.02507924],\n",
       "       [0.98510154, 0.01489846],\n",
       "       [0.98102603, 0.01897397],\n",
       "       [0.99317557, 0.00682443],\n",
       "       [0.98751195, 0.01248805],\n",
       "       [0.99268768, 0.00731232],\n",
       "       [0.95926835, 0.04073165],\n",
       "       [0.9219158 , 0.0780842 ],\n",
       "       [0.82269312, 0.17730688],\n",
       "       [0.92461431, 0.07538569],\n",
       "       [0.9835352 , 0.0164648 ],\n",
       "       [0.83082035, 0.16917965],\n",
       "       [0.98998575, 0.01001425],\n",
       "       [0.90236712, 0.09763288],\n",
       "       [0.91372599, 0.08627401],\n",
       "       [0.98655487, 0.01344513],\n",
       "       [0.74189733, 0.25810267],\n",
       "       [0.99480095, 0.00519905],\n",
       "       [0.98366892, 0.01633108],\n",
       "       [0.95721498, 0.04278502],\n",
       "       [0.98590706, 0.01409294],\n",
       "       [0.99627502, 0.00372498],\n",
       "       [0.89898455, 0.10101545],\n",
       "       [0.99639741, 0.00360259],\n",
       "       [0.99127398, 0.00872602],\n",
       "       [0.9919753 , 0.0080247 ],\n",
       "       [0.95652823, 0.04347177],\n",
       "       [0.94750884, 0.05249116],\n",
       "       [0.98465514, 0.01534486],\n",
       "       [0.98801093, 0.01198907],\n",
       "       [0.98583684, 0.01416316],\n",
       "       [0.94798993, 0.05201007],\n",
       "       [0.95070662, 0.04929338],\n",
       "       [0.95768386, 0.04231614],\n",
       "       [0.9265304 , 0.0734696 ],\n",
       "       [0.93077498, 0.06922502],\n",
       "       [0.94967271, 0.05032729],\n",
       "       [0.99028678, 0.00971322],\n",
       "       [0.99471181, 0.00528819],\n",
       "       [0.8689801 , 0.1310199 ],\n",
       "       [0.97506611, 0.02493389],\n",
       "       [0.95242069, 0.04757931],\n",
       "       [0.98053782, 0.01946218],\n",
       "       [0.99064161, 0.00935839],\n",
       "       [0.99512165, 0.00487835],\n",
       "       [0.91804316, 0.08195684],\n",
       "       [0.97014042, 0.02985958],\n",
       "       [0.98694605, 0.01305395],\n",
       "       [0.94036507, 0.05963493],\n",
       "       [0.99607832, 0.00392168],\n",
       "       [0.9169958 , 0.0830042 ],\n",
       "       [0.96043882, 0.03956118],\n",
       "       [0.99498679, 0.00501321],\n",
       "       [0.98104901, 0.01895099],\n",
       "       [0.98730973, 0.01269027],\n",
       "       [0.99654372, 0.00345628],\n",
       "       [0.94189346, 0.05810654],\n",
       "       [0.95684739, 0.04315261],\n",
       "       [0.99129639, 0.00870361],\n",
       "       [0.98484097, 0.01515903],\n",
       "       [0.98390939, 0.01609061],\n",
       "       [0.91002407, 0.08997593],\n",
       "       [0.98065148, 0.01934852],\n",
       "       [0.98127287, 0.01872713],\n",
       "       [0.91869981, 0.08130019],\n",
       "       [0.9744431 , 0.0255569 ],\n",
       "       [0.9222305 , 0.0777695 ],\n",
       "       [0.9571126 , 0.0428874 ],\n",
       "       [0.97694942, 0.02305058],\n",
       "       [0.97779451, 0.02220549],\n",
       "       [0.95728092, 0.04271908],\n",
       "       [0.98243684, 0.01756316],\n",
       "       [0.92403316, 0.07596684]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we fitted data into 3 models (nunique of y variable is 3). Data fitted,\n",
    "\tFor model1 is y = 0 , y != 0 (equal number of rows as in y = 0)\n",
    "\tFor model2 is y = 1 , y != 1 (equal number of rows as in y = 1)\n",
    "\tFor model3 is y = 2 , y != 2 (equal number of rows as in y = 2)\n",
    "- Each model does prediction on the same test data set.\n",
    "- predict_values will have the probabilities of 'yes' and 'no' for each record in the test data set. \n",
    "- We pick all the 'yes' probabilities. Find the argument of the maximum probability. Let's imagine the argmax for a given row is 1 , this mean that the model2 gave the best result and hence the predicted y value for that row is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.670</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   41.59</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 Apr 2020</td> <th>  Prob (F-statistic):</th>          <td>1.76e-22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:54:06</td>     <th>  Log-Likelihood:    </th>          <td> -252.89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th>          <td>   515.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    95</td>      <th>  BIC:               </th>          <td>   528.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.1520</td> <td>    0.093</td> <td>    1.627</td> <td> 0.107</td> <td>   -0.033</td> <td>    0.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.1160</td> <td>    0.093</td> <td>    1.247</td> <td> 0.216</td> <td>   -0.069</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.1536</td> <td>    0.102</td> <td>    1.508</td> <td> 0.135</td> <td>   -0.049</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>    0.2146</td> <td>    0.107</td> <td>    2.014</td> <td> 0.047</td> <td>    0.003</td> <td>    0.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>    0.2962</td> <td>    0.088</td> <td>    3.361</td> <td> 0.001</td> <td>    0.121</td> <td>    0.471</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.708</td> <th>  Durbin-Watson:     </th> <td>   1.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>   4.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.049</td> <th>  Prob(JB):          </th> <td>   0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.005</td> <th>  Cond. No.          </th> <td>    4.08</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.686\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.670\n",
       "Method:                 Least Squares   F-statistic:                              41.59\n",
       "Date:                Sat, 11 Apr 2020   Prob (F-statistic):                    1.76e-22\n",
       "Time:                        22:54:06   Log-Likelihood:                         -252.89\n",
       "No. Observations:                 100   AIC:                                      515.8\n",
       "Df Residuals:                      95   BIC:                                      528.8\n",
       "Df Model:                           5                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.1520      0.093      1.627      0.107      -0.033       0.338\n",
       "x2             0.1160      0.093      1.247      0.216      -0.069       0.301\n",
       "x3             0.1536      0.102      1.508      0.135      -0.049       0.356\n",
       "x4             0.2146      0.107      2.014      0.047       0.003       0.426\n",
       "x5             0.2962      0.088      3.361      0.001       0.121       0.471\n",
       "==============================================================================\n",
       "Omnibus:                       13.708   Durbin-Watson:                   1.781\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):                4.167\n",
       "Skew:                           0.049   Prob(JB):                        0.125\n",
       "Kurtosis:                       2.005   Cond. No.                         4.08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "\n",
    "x=pd.DataFrame(np.random.randint(0,10,(100,5)))\n",
    "x.columns=['x1','x2','x3','x4','x5']\n",
    "y=np.random.randint(0,10,100)\n",
    "### extra information as opposed to models\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as sfa\n",
    "model=sm.OLS(y,x)\n",
    "lm=model.fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA - Analysis of variance\n",
    "\n",
    "SST - Treatment variation\n",
    "\n",
    "Skewness\n",
    "\n",
    "Kurbosis\n",
    "\n",
    "<img src='img/skewness.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Read all the concepts above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recording at https://drive.google.com/open?id=1Ur-GFmT2vp17mtG8fo3Qrpd7WqFG7AAE \n",
    "\n",
    "https://drive.google.com/open?id=1Ur-GFmT2vp17mtG8fo3Qrpd7WqFG7AAE \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
